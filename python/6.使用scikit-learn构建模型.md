## 使用sklearn转换器处理数据

### 加载datasets模块中的数据集

```python
from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()##将数据集赋值给iris变量
print('breast_cancer数据集的长度为：',len(cancer))
print('breast_cancer数据集的类型为：',type(cancer))

# 此处为 sklearn自带的数据集
```

### 将数据集划分为训练集和测试集

一般将样本划分为：训练集、验证集和测试集，典型的占比为50%、25%、25%。

当数据总量较少时，常用的方法时留少部分做测试集，然后对其余N个样本采用K折交叉验证法。基本步骤为：将样本打乱，然后均匀分成K份，轮流选择其中K-1份做训练，剩余的一份做验证，计算预测误差平方和，最后把K次的预测误差平方和的均值作为选择最优模型结构的依据。

sklearn的model_selection模块提供了train_test_split函数，能够对数据集进行拆分：

其参数有arrays：接收一个或多个数据集。若为分类回归，则分别传入数据和标签；若为聚类，则传入数据

```python
from sklearn.model_selection import train_test_split
cancer_data_train, cancer_data_test,\
cancer_target_train, cancer_target_test = \
train_test_split(cancer_data, cancer_target, 
    test_size=0.2, random_state=42)
print('训练集数据的形状为：',cancer_data_train.shape)
print('训练集标签的形状为：',cancer_target_train.shape)
print('测试集数据的形状为：',cancer_data_test.shape)
print('测试集标签的形状为：',cancer_target_test.shape)
```

### 使用sklearn转换器进行数据预处理与降维

使用sklearn转换器能够实现对传入的numpy数组进行标准化处理、归一化处理、二值化处理和PCA降维等操作。

#### 离差标准化

```python
import numpy as np
from sklearn.preprocessing import MinMaxScaler
Scaler = MinMaxScaler().fit(cancer_data_train) ##生成规则
##将规则应用于训练集
cancer_trainScaler = Scaler.transform(cancer_data_train) 
##将规则应用于测试集
cancer_testScaler = Scaler.transform(cancer_data_test)
print('离差标准化前训练集数据的最小值为：',np.min(cancer_data_train))
print('离差标准化后训练集数据的最小值为：',np.min(cancer_trainScaler))
print('离差标准化前训练集数据的最大值为：',np.max(cancer_data_train))
print('离差标准化后训练集数据的最大值为：',np.max(cancer_trainScaler))
print('离差标准化前测试集数据的最小值为：',np.min(cancer_data_test))
print('离差标准化后测试集数据的最小值为：',np.min(cancer_testScaler))
print('离差标准化前测试集数据的最大值为：',np.max(cancer_data_test))
print('离差标准化后测试集数据的最大值为：',np.max(cancer_testScaler))
```

#### 对breast_cancer数据集PCA降维

```python
from sklearn.decomposition import PCA
pca_model = PCA(n_components=10).fit(cancer_trainScaler) ##生成规则
cancer_trainPca = pca_model.transform(cancer_trainScaler) ##将规则应用于训练集
cancer_testPca = pca_model.transform(cancer_testScaler) ##将规则应用于测试集
print('PCA降维前训练集数据的形状为：',cancer_trainScaler.shape)
print('PCA降维后训练集数据的形状为：',cancer_trainPca.shape)
print('PCA降维前测试集数据的形状为：',cancer_testScaler.shape)
print('PCA降维后测试集数据的形状为：',cancer_testPca.shape)
```

## 构建并评价聚类模型

### 使用sklearn估计器构建聚类模型

sklearn估计器中拥有fit和predict两个方法。

```python
from sklearn.datasets import load_iris
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
iris = load_iris()
iris_data = iris['data'] ##提取数据集中的特征
iris_target = iris['target'] ## 提取数据集中的标签
iris_names = iris['feature_names'] ### 提取特征名
scale = MinMaxScaler().fit(iris_data)## 训练规则
iris_dataScale = scale.transform(iris_data) ## 应用规则
kmeans = KMeans(n_clusters = 3,
    random_state=123).fit(iris_dataScale) ##构建并训练模型
print('构建的K-Means模型为：\n',kmeans)

result = kmeans.predict([[1.5,1.5,1.5,1.5]])
print('花瓣花萼长度宽度全为1.5的鸢尾花预测类别为：', result[0])
```

通过sklearn的manifold模块中的TSNE函数可以实现多维数组的可视化展示

```python
import pandas as pd
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
##使用TSNE进行数据降维,降成两维
tsne = TSNE(n_components=2,init='random',
    random_state=177).fit(iris_data)
df=pd.DataFrame(tsne.embedding_) ##将原始数据转换为DataFrame
df['labels'] = kmeans.labels_ ##将聚类结果存储进df数据表
##提取不同标签的数据
df1 = df[df['labels']==0]
df2 = df[df['labels']==1] 
df3 = df[df['labels']==2] 
## 绘制图形
fig = plt.figure(figsize=(9,6)) ##设定空白画布，并制定大小
##用不同的颜色表示不同数据
plt.plot(df1[0],df1[1],'bo',df2[0],df2[1],'r*',
    df3[0],df3[1],'gD')
plt.savefig('../tmp/聚类结果.png') 
plt.show() ##显示图片
```

### 评价聚类模型

组内相似度越大，组间差别越大，聚类效果越好。

聚类模型评价指标：

* ARI评价法（最佳值：1）
* AMI评价法（最佳值：1）
* V-measure评分（最佳值：1）
* FMI评价法（最佳值：1）
* 轮廓系数评价法
* Calinski-Harabasz指数评价法

```python
from sklearn.metrics import fowlkes_mallows_score
for i in range(2,7):
    ##构建并训练模型
    kmeans = KMeans(n_clusters = i,random_state=123).fit(iris_data)
    score = fowlkes_mallows_score(iris_target,kmeans.labels_)
    print('iris数据聚%d类FMI评价分值为：%f' %(i,score))
```

## 构建并评价分类模型

分类是指构造一个分类模型，输入样本的特征值，输出对应的类型，将每个样本映射到预先定义好的类别。

### 使用sklearn估计器构建分类模型

```python
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
cancer = load_breast_cancer()
cancer_data = cancer['data']
cancer_target = cancer['target']
cancer_names = cancer['feature_names']
## 将数据划分为训练集测试集
cancer_data_train,cancer_data_test, \
cancer_target_train,cancer_target_test = \
train_test_split(cancer_data,cancer_target,
      test_size = 0.2,random_state = 22)
## 数据标准化
stdScaler = StandardScaler().fit(cancer_data_train)
cancer_trainStd = stdScaler.transform(cancer_data_train)
cancer_testStd = stdScaler.transform(cancer_data_test)

## 建立SVM模型
svm = SVC().fit(cancer_trainStd,cancer_target_train)

print('建立的SVM模型为：\n',svm)
```

```python
cancer_target_pred = svm.predict(cancer_testStd)
print('预测前20个结果为：\n',cancer_target_pred[:20])
```

### 评价分类模型

```python
from sklearn.metrics import accuracy_score,precision_score, \
recall_score,f1_score,cohen_kappa_score
print('使用SVM预测breast_cancer数据的准确率为：',
      accuracy_score(cancer_target_test,cancer_target_pred))
print('使用SVM预测breast_cancer数据的精确率为：',
      precision_score(cancer_target_test,cancer_target_pred))
print('使用SVM预测breast_cancer数据的召回率为：',
      recall_score(cancer_target_test,cancer_target_pred))
print('使用SVM预测breast_cancer数据的F1值为：',
      f1_score(cancer_target_test,cancer_target_pred))
print('使用SVM预测breast_cancer数据的Cohen’s Kappa系数为：',
      cohen_kappa_score(cancer_target_test,cancer_target_pred))
```

sklearn的metrics模块还提供了一个能输出分类模型评价报告的函数classification_report

```python
from sklearn.metrics import classification_report
print('使用SVM预测iris数据的分类报告为：','\n',
      classification_report(cancer_target_test,
            cancer_target_pred))
```

绘制ROC曲线

```python
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

## 求出ROC曲线的x轴和y轴
fpr, tpr, thresholds = \
roc_curve(cancer_target_test,cancer_target_pred)

plt.figure(figsize=(10,6))
plt.xlim(0,1) ##设定x轴的范围
plt.ylim(0.0,1.1) ## 设定y轴的范围
plt.xlabel('False Postive Rate')
plt.ylabel('True Postive Rate')

plt.plot(fpr,tpr,linewidth=2, linestyle="-",color='red')

plt.show()
```

通常情况下，ROC曲线与X轴形成的面积越大，表示模型性能越好；

## 构建并评价回归模型

分类和回归的主要区别在于：分类算法的标签是离散的，回归算法的标签是连续的

使用sklearn估计器构建线性回归模型

```python
##加载所需函数
from sklearn.linear_model import LinearRegression
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
## 加载boston数据
boston = load_boston()
X = boston['data']
y = boston['target']
names = boston['feature_names']
## 将数据划分为训练集测试集
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=125)
## 建立线性回归模型
clf = LinearRegression().fit(X_train,y_train)
print('建立的LinearRegression模型为：','\n',clf)

## 预测训练集结果
y_pred = clf.predict(X_test)
print('预测前20个结果为：','\n',y_pred[:20])
```

回归结果可视化

```python
import matplotlib.pyplot as plt
from matplotlib import rcParams
rcParams['font.sans-serif'] = 'SimHei'
fig = plt.figure(figsize=(10,6)) ##设定空白画布，并制定大小
##用不同的颜色表示不同数据
plt.plot(range(y_test.shape[0]),y_test,color="blue", linewidth=1.5, linestyle="-")
plt.plot(range(y_test.shape[0]),y_pred,color="red", linewidth=1.5, linestyle="-.")
plt.legend(['真实值','预测值'])
plt.show() ##显示图片
```

### 评价回归模型

平均绝对误差、均方误差和中值绝对误差的值越靠近0，模型性能越好，可解释方差和R^2值越靠近1，模型性能越好。

```python
from sklearn.metrics import explained_variance_score,\
mean_absolute_error,\
mean_squared_error,\
median_absolute_error,r2_score
print('Boston数据线性回归模型的平均绝对误差为：',
     mean_absolute_error(y_test,y_pred))
print('Boston数据线性回归模型的均方误差为：',
     mean_squared_error(y_test,y_pred))
print('Boston数据线性回归模型的中值绝对误差为：',
     median_absolute_error(y_test,y_pred))
print('Boston数据线性回归模型的可解释方差值为：',
     explained_variance_score(y_test,y_pred))
print('Boston数据线性回归模型的R方值为：',
     r2_score(y_test,y_pred))
```







