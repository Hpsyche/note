## 读/写不同数据源的数据

pandas内置了10余种数据源读取函数和对应的数据写入函数。常见的数据源有3种，分别是数据库数据、文本文件和Excel文件。

### 读/写数据库数据

* read_sql

  以下两者的结合

* read_sql_table

  只能读取数据库的某一个表格，不能实现查询的操作

* read_sql_query

  实现查询，不能实现表格

```python
from sqlalchemy import create_engine
## 创建一个mysql连接器，用户名为root，密码为1234
## 地址为127.0.0.1，数据库名称为testdb，编码为utf-8
engine = create_engine('mysql+pymysql://root:460204715@127.0.0.1:3306/python_db?charset=utf8')
print(engine)
```

```python
detail1 = pd.read_sql_table('meal_order_detail1',con = engine)
print('使用read_sql_table读取订单详情表的长度为:',len(detail1))
```

### 数据库数据存储

数据存储函数：DataFrame.to_sql

```python
detail1.to_sql('test1',con = engine,index = False,
      if_exists = 'replace')
## 使用read_sql读取test表
formlist1 = pd.read_sql_query('show tables',con = engine)
print('新增一个表格后testdb数据库数据表清单为：','\n',formlist1)
```

### 读/写文本文件

CSV是一种用分隔符分割的文件格式，因为其分隔符不一定是逗号，因此也被称为字符分割文件。

#### 文件文本读取

* pandas.read_table
* pandas.read_csv

以上两个函数多数的参数一致，在sep（分隔符）上，read_csv默认为，read_table默认为Tab。

（如果分隔符错误，在读取数据的时候，每一行数据将连成一片）

```python
order1 = pd.read_csv('meal_order_info.csv',
      encoding = 'gbk')
print('使用read_csv读取的订单信息表的长度为：',order1)
```

#### 文件文本存储

DataFrame.to_csv

```python
import os
print('订单信息表写入文本文件前目录内文件列表为：\n',
      os.listdir('tmp'))
## 将order以csv格式存储
order.to_csv('tmp/orderInfo.csv',sep = ';',index = False) 
print('订单信息表写入文本文件后目录内文件列表为：\n',
      os.listdir('tmp'))
```

### 读/写Excel文件

#### Excel文件读取

DataFrame.read_excel

```python
user = pd.read_excel('users.xlsx')## 读取user.xlsx文件
print('客户信息表长度为：',len(user))
```

#### Excel文件存储

DataFrame.to_excel

```python
print('客户信息表写入excel文件前目录内文件列表为：\n',
      os.listdir('tmp'))
user.to_excel('tmp/userInfo.xlsx')
print('客户信息表写入excel文件后目录内文件列表为：\n',
      os.listdir('tmp'))
```

## 掌握DataFrame的常用操作

### DataFrame常用属性

* values：元素
* index：索引
* columns：列名
* dtypes：类型
* size：元素个数
* ndim：维度数
* shape：数据形状
* T：实现转置

### 查改增删DataFrame数据

#### 查看访问DataFrame中的数据

##### DataFrame数据的基本查看方式

DataFrame是一个带有标签的二维数组，每个标签相当于每一列的列名。

访问内部数据：

* 字典访问

  ```python
  order_id = detail['order_id']
  print('订单详情表中的order_id的形状为:','\n',order_id.shape)
  ```

* 属性访问

  ```python
  dishes_name = detail.dishes_name
  print('订单详情表中的dishes_name的形状为:',dishes_name.shape)
  ```

访问一个Series基本和访问一个ndarray相同，如下：

```python
dishes_name5 = detail['dishes_name'][:5]
print('订单详情表中的dishes_name前5个元素为：','\n',dishes_name5)
```

##### DataFrame的loc、iloc访问方式

* DataFrame.loc[行索引名称或条件，类索引名称]
* DateFrame.ioc[行索引位置，列索引位置]

```python
print('列名为order_id和dishes_name的行名为3的数据为：\n',
      detail.loc[3,['order_id','dishes_name']])
print('列名为order_id和dishes_name行名为2,3,4,5,6的数据为：\n',
      detail.loc[2:6,['order_id','dishes_name']])
print('列位置为1和3行位置为3的数据为：\n',detail.iloc[3,[1,3]])
print('列位置为1和3行位置为2,3,4,5,6的数据为：\n',
      detail.iloc[2:7,[1,3]])
```

注意：在使用loc方法的时候，如果内部传入的行索引名称为一区间，则前后均为闭区间；使用iloc方法时，如果内部传入的行索引位置或列索引位置为区间，则为前闭后开区间。

loc内部还可以传入表达式，结果会返回满足表达式的所有值

```python
print('detail中order_id为458的dishes_name为：\n',
     detail.loc[detail['order_id']=='458',
     ['order_id','dishes_name']])
```

loc更加灵活多变，代码的可读性更高；iloc的代码简洁，但可读性不高。大多数建议使用loc方法。

##### 切点方法之ix

ix更像是loc和iloc两种方法的融合。其既可以接收索引名称，也可以接收索引位置。如下：

* DataFrame.ix[行索引的名称或位置或条件，列索引名称或位置]

  使用ix方法需要注意，当索引名称和位置存在部分重叠时，ix默认优先识别名称。

ix使用方便，但在面对数据量巨大的任务的时候，其效率低于loc和iloc方法，所以在日常中建议使用loc和iloc方法来执行切片操作。

#### 更改DataFrame中的数据

重新赋值即可

```python
detail.loc[detail['order_id']=='458','order_id'] = '45800'
print('更改后detail中order_id为458的order_id为：\n',
     detail.loc[detail['order_id']=='458','order_id'])
print('更改后detail中order_id为45800的order_id为：\n',
     detail.loc[detail['order_id']=='45800','order_id'])
```

#### 为DataFrame增添数据

为DataFrame添加一列，只需要新建一个列索引，并对该索引下的数据进行赋值操作即可

```python
detail['payment'] =  detail['counts']*detail['amounts']
print('detail新增列payment的前五行为：','\n',
      detail['payment'].head())
```

如果新增的一列值时相同的，则直接为其赋值一个常量即可：

```python
detail['pay_way'] = '现金支付'
print('detail新增列pay_way的前五行为：','\n',
      detail['pay_way'].head())
```

#### 删除某列或某行数据

##### 删除某列数据

```python
print('删除pay_way前deatil的列索引为：','\n',detail.columns)

# 删除标签为'pay_way'的一列，操作为纵向，对原数据生效
detail.drop(labels = 'pay_way',axis = 1,inplace = True)

print('删除pay_way后detail的列索引为：','\n',detail.columns)
```

##### 删除某行数据

只需要将drop方法参数中的‘labels'参数换成对应的行索引，将'axis'参数设置为0即可，即：

```python
print('删除1-10行前detail的长度为：',len(detail))
detail.drop(labels = range(1,11),axis = 0,inplace = True)
print('删除1-10行后detail的列索引为：',len(detail))
```

### 描述分析DataFrame数据

#### 数值型特征的描述性统计

* np.min：最小值
* np.max：最大值
* np.mean：均值
* np.ptp：极差
* np.median：中位数
* np.std：标准差
* np.var：方差
* np.cov：协方差

```python
import numpy as np
print('订单详情表中amount（价格）的平均值为：', np.mean(detail['amounts']))
```

pandas提供了更加便利的方法来进行数值型数据的统计，上述用np.mean方法实现求均值，也可以通过pandas实现，如下：

```python
print('订单详情表中amount（价格）的平均值为：', detail['amounts'].mean())
```

pandas还提供了一个叫describe的方法，能够一次性得出数据框中所有数值型特征的非空值数目、均值、四分位数和标准差。

```python
print('订单详情表counts和amounts两列的描述性统计为：\n',
      detail[['counts','amounts']].describe())

//output:
订单详情表counts和amounts两列的描述性统计为：
             counts      amounts
count  2769.000000  2769.000000
mean      1.111593    45.343084
std       0.626521    36.841316
min       1.000000     1.000000
25%       1.000000    25.000000
50%       1.000000    35.000000
75%       1.000000    56.000000
max      10.000000   178.000000
```

#### 类别型特征的描述性统计

如：value_counts：可以求出频数统计排名结果

```python
print('订单详情表dishes_name频数统计结果前10为：\n',
      detail['dishes_name'].value_counts()[0:10])

//output:
订单详情表dishes_name频数统计结果前10为：
 白饭/大碗        92
凉拌菠菜         77
...............
```

pandas还提供了category类，可以使用astype方法将目标特征的数据类型转换为category类型，如下：

```python
detail['dishes_name'] = detail['dishes_name'].astype('category')
print('订单信息表dishes_name列转变数据类型后为：',detail['dishes_name'].dtypes)

//output:
订单信息表dishes_name列转变数据类型后为： category
```

在category类中，describe统计结果分别为：列非空元素的数目、类别的数目、数目最多的类别和数目最多类别的数目。

```python
print('订单信息表dishes_name的描述统计结果为：\n',
      detail['dishes_name'].describe())

//output:
订单信息表dishes_name的描述统计结果为：
 count      2779
unique      145
top       白饭/大碗
freq         92
Name: dishes_name, dtype: object5
```

## 转换与处理时间序列数

数据分析的对象不仅仅限于数值型与类别型两种，常用的数据类型还包括了时间类型，通过时间类型数据能够获取到对应的年月日的星期等信息。

在多数情况下，会将与时间相关的字符串转换为TimeStamp，pandas提供了to_datetime函数

### 转换字符串时间为标准时间

```python
import pandas as pd
order = pd.read_table('meal_order_info.csv',
      sep = ',',encoding = 'gbk')
print('进行转换前订单信息表lock_time的类型为：', 
      order['lock_time'].dtypes)
order['lock_time'] = pd.to_datetime(order['lock_time'])
print('进行转换后订单信息表lock_time的类型为：', 
      order['lock_time'].dtypes)

//output:
进行转换前订单信息表lock_time的类型为： object
进行转换后订单信息表lock_time的类型为： datetime64[ns]
```

还可以将数据单独取出来，转换为DatatimeIndex（一系列时间点的一种数据结构）或者PeriodIndex类型（一系列时间段的数据结构）

```python
dateIndex = pd.DatetimeIndex(order['lock_time'])
print('转换为DatetimeIndex后数据的类型为：\n',type(dateIndex))

periodIndex = pd.PeriodIndex(order['lock_time'],freq = 'S')
print('转换为DatetimeIndex后数据的类型为：\n',type(periodIndex))
```

### 提取时间序列数据信息

对DataFrame某一列时间信息数据的提取

```python
year1 = [i.year for i in order['lock_time']]
print('lock_time中的年份数据前5个为：',year1[:5])
```

提取DatetimeIndex和PeriodIndex中的信息

```python
print('dateIndex中的星期名称数据前5个为：\n',
      dateIndex.weekday_name[:5])
print('periodIndex中的星期标号数据前5个为：',
      periodIndex.weekday[:5])
```

### 加减时间数据

涉及pandas的Timedelta类，其为一个异类，不仅能使用正数，也可以使用负数。

```python
time1 = order['lock_time']+pd.Timedelta(days = 1) 
print('lock_time在加上一天前前5行数据为：\n',order['lock_time'][:5])
print('lock_time在加上一天前前5行数据为：\n',time1[:5])
```

## 使用分组聚合进行组内计算

pandas提供了一个灵活高效的groupby方法，配合agg和apply方法，能够实现分组聚合的操作。

### 使用groupby方法拆分数据

```python
detail = pd.read_sql_table('meal_order_detail1',con = engine)
detailGroup = detail[['order_id','counts',
      'amounts']].groupby(by = 'order_id')
print('分组后的订单详情表为：',detailGroup)
```

groupBy类求均值等

```python
print('订单详情表分组后前5组每组的均值为：\n', 
      detailGroup.mean().head())
```

### 使用agg方法聚合数据

```python
print('订单详情表的菜品销量与售价的和与均值为：\n',
      detail[['counts','amounts']].agg([np.sum,np.mean]))
print('订单详情表的菜品销量总和与售价的均值为：\n',
      detail.agg({'counts':np.sum,'amounts':np.mean}))
print('菜品订单详情表的菜品销量总和与售价的总和与均值为：\n',
      detail.agg({'counts':np.sum,'amounts':[np.mean,np.sum]}))

//output:
订单详情表的菜品销量与售价的和与均值为：
            counts        amounts
sum   3088.000000  125992.000000
mean     1.111191      45.337172
订单详情表的菜品销量总和与售价的均值为：
 counts     3088.000000
amounts      45.337172
dtype: float64
菜品订单详情表的菜品销量总和与售价的总和与均值为：
       counts        amounts
mean     NaN      45.337172
sum   3088.0  125992.000000
```

自定义函数：

```python
def DoubleSum(data):
    s = data.sum()*2
    return s
print('菜品订单详情表的菜品销量两倍总和为：','\n',
      detail.agg({'counts':DoubleSum},axis = 0))

print('订单详情表的菜品销量与售价的和的两倍为：\n',
      detail[['counts','amounts']].agg(DoubleSum1))
```

```python
print('订单详情表分组后前3组每组的均值为：\n', 
      detailGroup.agg(np.mean).head(3))
```

### 使用apply方法聚合数据

* apply方法只能作用与整个DataFrame或者Serial，不能够实现不同的字段应用不同的函数
* agg能够对应不同字段应用不同函数来获取不同结果，使用agg方法能够实现不同的字段应用不同的函数

使用方式和agg相同

```python
print('订单详情表的菜品销量与售价的均值为：\n',
      detail[['counts','amounts']].apply(np.mean))
```

### 使用transform方法聚合数据

fransform方法能够对整个DataFrame的所有元素进行操作，其只有一个参数"func"，表示对DataFrame操作的函数。

```python
print('订单详情表的菜品销量与售价的两倍为：\n',
      detail[['counts','amounts']].transform(
            lambda x:x*2).head(4))
```

## 创建透视图与交叉表

数据透视图：根据一个或多个键值对数据进行聚合，根据行或列的分组键将数据划分到各个域。

### 使用pivot_table函数创建透视图

```python
# index：表示行分组键；columns：表示列分组键；aggfunc：表示聚合函数
# 即：用order_id作为分组键创建的订单透视图
detailPivot = pd.pivot_table(detail[[
      'order_id','counts','amounts']],
      index = 'order_id')
print('以order_id作为分组键创建的订单透视表为：\n',
       detailPivot.head())
```

```python
detailPivot2 = pd.pivot_table(detail[[
      'order_id','dishes_name','counts','amounts']],
      index = 'order_id',
      columns = 'dishes_name',
      aggfunc = np.sum)
print('以order_id和dishes_name作为行列分组键创建的\
透视表前5行4列为：\n',detailPivot2.iloc[:5,:4])
```

当全部数据很多时，若只要显示自己关心的列，可以通过制定values参数来实现

```python
detailPivot4 = pd.pivot_table(detail[[
      'order_id','dishes_name','counts','amounts']],
      index = 'order_id',
      values = 'counts',
      aggfunc = np.sum)
print('以order_id作为行分组键counts作为值创建的\
透视表前5行为：\n',detailPivot4.head())
```

当数据不存在时，会自动填充NaN，可以通过fill_value参数，表示当存在缺失值时以指定数值进行填充

```python
detailPivot5 = pd.pivot_table(detail[[
      'order_id','dishes_name','counts','amounts']],
      index = 'order_id',
      columns = 'dishes_name',
      aggfunc = np.sum,fill_value = 0)
print('空值填0后以order_id和dishes_name为行列分组键\
创建透视表前5行4列为：\n',detailPivot5.iloc[:5,:4])
```

若如下margins=True，结果会出现All列

### 使用crosstab函数创建交叉表

交叉表主要用于计算分组频率。

```python
# 参数：index：行索引建；columns：列索引建；values：聚合数据；aggfunc：聚合函数
detailCross = pd.crosstab(
      index=detail['order_id'],
      columns=detail['dishes_name'],
      values = detail['counts'],aggfunc = np.sum)
print('以order_id和dishes_name为分组键\
counts为值的透视表前5行5列为：\n',detailCross.iloc[:5,:5])
```



























