在计算机里，我们也可以用一样的办法，用科学计数法来表示实数。浮点数的科学计数法的表示，有一个IEEE的标准，它定义了两个基本的格式。一个是用32比特表示单精度的浮点数，也就是我们常常说的float或者float32类型。另外一个是用64比特表示双精度的浮点数，也就是我们平时说的double或者float64类型。

双精度类型和单精度类型差不多，这里，我们来看单精度类型，双精度你自然也就明白了。

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\15-1.PNG)

单精度的32个比特可以分成三部分。

* 第一部分是一个符号位，用来表示是正数还是负数。我们一般用s来表示。在浮点数里，我们不像正数分符号数还是无符号数，所有的浮点数都是有符号的。
* 接下来是一个8个比特组成的指数位。我们一般用e来表示。8个比特能够表示的整数空间，就是0～255。我们在这里用1～254映射到-126～127这254个有正有负的数上。因为我们的浮点数，不仅仅想要表示很大的数，还希望能够表示很小的数，所以指数位也会有负数。
* 最后，是一个23个比特组成的有效数位。我们用f来表示。综合科学计数法，我们的浮点数就可以表示成下面这样：

> $(-1)^s×1.f×2^e$

你会发现，这里的浮点数，没有办法表示0。的确，要表示0和一些特殊的数，我们就要用上在e里面留下的0和255这两个表示，这两个表示其实是两个标记位。在e为0且f为0的时候，我们就把这个浮点数认为是0。至于其它的e是0或者255的特殊情况，你可以看下面这个表格，分别可以表示出无穷大、无穷小、NAN以及一个特殊的不规范数。

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\15-2.PNG)

我们可以以0.5为例子。0.5的符号为s应该是0，f应该是0，而e应该是-1，也就是
$0.5= (-1)^0×1.0×2^{-1}=0.5$，对应的浮点数表示，就是32个比特。

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\15-3.PNG)

## 总结延伸

回到我们最开头，为什么我们用0.3 + 0.6不能得到0.9呢？这是因为，**浮点数没有办法精确表示0.3、0.6和0.9。事实上，我们拿出0.1～0.9这9个数，其中只有0.5能够被精确地表示成二进制的浮点数，也就是s =0、e = -1、f = 0这样的情况。**

## 浮点数的二进制转化

十进制的浮点数怎么表示成二进制。

比方说，我们输入了一个十进制浮点数9.1。那么按照之前的讲解，在二进制里面，我们应该把它变成一个“符号位s+指数位e+有效位数f”的组合。

首先，我们把这个数的整数部分，变成一个二进制。这个我们前面讲二进制的时候已经讲过了。这里的9，换算之后就是1001。

接着，我们把对应的小数部分也换算成二进制。小数怎么换成二进制呢？我们先来定义一下，小数的二进制表示是怎么回事。

* 我们拿0.1001这样一个二进制小数来举例说明。和上面的整数相反，我们把小数点后的每一位，都表示对应的2的-N次方。那么0.1001，转化成十进制就是：

  $1×2^{-1}+0×2^{-2}+0×2^{-3}+$
  $1×2^{-4}=0.5625$

和整数的二进制表示采用“除以2，然后看余数”的方式相比，**小数部分转换成二进制是用一个相似的反方向操作，就是乘以2，然后看看是否超过1。如果超过1，我们就记下1，并把结果减去1，进一步循环操作。**在这里，我们就会看到，0.1其实变成了一个无限循环的二进制小数，0.000110011。这里的“0011”会无限循环下去。

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\15-4.PNG)\

然后，我们把整数部分和小数部分拼接在一起，9.1这个十进制数就变成了1001.000110011…这样一个二进制表示。

上一讲我们讲过，浮点数其实是用二进制的科学计数法来表示的，所以我们可以把小数点左移三位，这个数
就变成了：

> $1.0010$$0011$$0011… × 2^3$

因为指数位有正又有负，所以指数位在127之前代表负数，之后代表正数，那3其实对应的是加上127的偏移量130，转化成二进制，就是130，对应的就是指数位的二进制，表示出来就是10000010。

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\15-5.PNG)

然后，我们把“s+e+f”拼在一起，就可以得到浮点数9.1的二进制表示了。

即：010000010 0010 0011001100110011 001

如果我们再把这个浮点数表示换算成十进制， 实际准确的值是9.09999942779541015625。相信你现在应该不会感觉奇怪了。

这个也解释了为什么，在上一讲一开始，0.3+0.6=0.899999。**因为0.3转化成浮点数之后，和这里的9.1一
，并不是精确的0.3了，0.6和0.9也是一样的，最后的计算会出现精度问题。**

## 浮点数的加法和精度损失

浮点数的加法是怎么进行的。原理也很简单：先对齐、再计算。

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\15-6.PNG)

**32位浮点数的有效位长度一共只有23位，如果两个数的指数位差出23位，较小的数右移24位之后，所有的有效位就都丢失了**。这也就意味着，虽然浮点数可以表示上到$3.40×10^{38}$，下到$1.17×10^{-38}$这样的数值范围。但是在实际计算的时候，**只要两个数，差出$2^{24}$，也就是差不多1600万倍，那这两个数相加之后，结果完全不会变化。**

你可以试一下，我下面用一个简单的Java程序，让一个值为2000万的32位浮点数和1相加，你会发现，+1这个过程因为精度损失，被“完全抛弃”了。

```java
public class FloatPrecision {
    public static void main(String[] args) {
        float a = 20000000.0f;
        float b = 1.0f;
        float c = a + b;
        System.out.println("c is " + c);
        float d = c - a;
        System.out.println("d is " + d);
    }
}
```

```tex
c is 2.0E7
d is 0.0
```

### Kahan Summation算法

一个常见的应用场景是，在一些“积少成多”的计算过程中，比如在机器学习中，我们经常要计算海量样本计算出来的梯度或者loss，于是会出现几亿个浮点数的相加。每个浮点数可能都差不多大，但是随着累积值的越来越大，就会出现“大数吃小数”的情况。

面对这个问题，聪明的计算机科学家们也想出了具体的解决办法。他们发明了一种叫作Kahan Summation的算法来解决这个问题。

其实这个算法的原理其实并不复杂，就是**在每次的计算过程中，都用一次减法，把当前加法计算中损失的精度记录下来，然后在后面的循环中，把这个精度损失放在要加的小数上，再做一次运算。**

