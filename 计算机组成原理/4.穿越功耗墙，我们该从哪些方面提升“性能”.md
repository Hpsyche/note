## 功耗：CPU的“人体极限”

相较于1978年到2000年，这20年里300倍的主频提升，从2000年到现在的这19年，CPU的主频只大概提高了3倍。发现主频提升已遇到较大的瓶颈。

而inter的产品奔腾4最终它的主频上限定格在3.8GHz。奔腾4的主频为什么没能超过3.8GHz的障碍呢？答案就是功耗问题。什么是功耗问题呢？我们先看一个直观的例子。

我们的CPU，一般都被叫作超大规模集成电路（Very-Large-Scale Integration，VLSI）。这些电路，实际上都是一个个晶体管组合而成的。**CPU在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能。**

想要计算得快，一方面，我们要在CPU里，同样的面积里面，多放一些晶体管，也就是增加密度；另一方面，我们要让晶体管“打开”和“关闭”得更快一点，也就是提升主频。

**而这两者，都会增加功耗，带来耗电和散热的问题。**

我们会在CPU上面抹硅脂、装风扇，乃至用上水冷或者其他更好的散热设备，就好像在工厂里面装风扇、空调，发冷饮一样。但是同样的空间下，装上风扇空调能够带来的散热效果也是有极限的。

因此，在CPU里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。一个CPU的功率，可以
用这样一个公式来表示：

> 功耗 ~= 1/2 ×负载电容×电压的平方×开关频率×晶体管数量

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\4-1.PNG)

但是，**功耗增加太多，就会导致CPU散热跟不上，这时，我们就需要降低电压。这里有一点非常关键，在整个功耗的公式里面，功耗和电压的平方是成正比的。这意味着电压下降到原来的1/5，整个的功耗会变成原来的1/25。**(矛盾点)

事实上，从5MHz主频的8086到5GHz主频的Intel	i9，CPU的电压已经从5V左右下降到了1V左右。**这也是为什么我们CPU的主频提升了1000倍，但是功耗只增长了40倍。（1000/25=40）**比如说，我写这篇文章用的是Surface Go，在这样的轻薄笔记本上，微软就是选择了把电压下降到0.25V的低电压CPU，使得笔记本能有更长的续航时间。

## 并行优化，理解阿姆达尔定律

ntel 意识到通过提升主频比较“难”去实现性能提升，便开始推出Core Duo 这样的多核 CPU，通过提升“吞吐率”而不是“响应时间”，来达到目的。提升响应时间。

就好比提升你的用的交通工具的速度，比如原本你是开汽车，现在变成了回车乃至飞机本来开车从上海到北京要20个小时，换成飞机需要2个小时了，但是在这之上，再想要提升速度就不太容易了，我们的CPU在奔腾4的年代，就好比已经到了飞机这个速度极限了，此时可以一次同时开2架、4架乃至8架飞机，这就好像我们现在用的2核、4核、乃至8核的CPU，虽然上海到北京的时间没有变，但是一次费8架飞机能够云的东西自然就变多了，也就是所谓的“吞吐率”变大了，所以，不管你有没有需要，现在的性能就是提升了2倍乃至8倍、16倍，

这个思想在很多地方都可以使用。举个例子，我们做机器学习程序的时候，需要计算向量的点积，比如向量$W	=	[W_0,	W_1,	W_2,	…,	W_{15}]$和向量	$X	=	[X_0,	X_1,	X_2,	…,	X_{15}]$，$W·X	=	W_0	*	X_0	+	W_1	*	X_1+$$W_2	*	X_2	+	…	+	W_{15} * X_{15}$。这些式子由16个乘法和1个连加组成。如果你自己一个人用笔来算的话，需要一步一步算16次乘法和15次加法。如果这个时候我们把这个人物分配给4个人，同时去算$W_0～W_3$, $W_4～W_7$, $W_8～W_{11}$, $W_{12}～W_{15}$这样四个部分的结果，再由一个人进行汇总，需要的时间就会缩短。

![](D:\Work\TyporaNotes\note\计算机组成原理\pict\4-2.PNG)

是，并不是所有问题，都可以通过并行提高性能来解决，如果想使用这种思想，需要满足这样几个条件。

* 需要进行的计算，本身可以分解成几个可以并行的任务，好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果
* 需要能够分解好问题，并确保几个人的结果能够汇总到一起
* 在汇总这个阶段，是没有办法进行的，还是得顺序执行，一步一步来

是，并不是所有问题，都可以通过并行提高性能来解决，如果想使用这种思想，需要满足这样几个条件。

**第一：需要进行的计算，本身可以分解成几个可以并行的任务，好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果**

**第二：需要能够分解好问题，并确保几个人的结果能够汇总到一起**

**第三：在汇总这个阶段，是没有办法进行的，还是得顺序执行，一步一步来**这个定

这个定律说的就是，对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。具体可以用这样一个公式来表示：

> 优化后的执行时间 = 受优化影响的执行时间/加速倍数+不受影响的执行时间

比如上面的各个向量的一小段的点积，需要100ns，加法需要20ns，总共需要120ns。这里通过并行4个CPU有了4倍的加速度。那么最终优化后，就有了100/4+20=45ns。即使我们增加更多的并行度来提供加速倍数，比如有100个CPU，整个时间也需要100/100+20=21ns。

## 总结延伸

在“摩尔定律”和“并行计算”之外，在整个计算机组成层面，还有这样几个原则性的性能提升方法。

### 加速大概率事件

最典型的就是，过去几年流行的深度学习，整个计算过程中，99%都是向量和矩阵计算，于是，工程师们通过用GPU替代CPU，大幅度提升了深度学习的模型训练过程。本来一个CPU需要跑几小时甚至几天的程序，GPU只需要几分钟就好了。Google更是不满足于GPU的性能，进一步地推出了TPU。

### 通过流水线提高性能。

现代的工厂里的生产线叫“流水线”。我们可以把装配iPhone这样的任务拆分成一个个细分的任务，让每个人都只需要处理一道工序，最大化整个工厂的生产效率。类似的，我们的CPU其实就是一个“运算工厂”。我们把CPU指令执行的过程进行拆分，细化运行，也是现代CPU在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一。

### 通过预测提高性能。

通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法。典型的例子就是在一个循环访问数组的时候，凭经验，你也会猜到下一步我们会访问数组的下一项。后面要讲的“分支和冒险”、“局部性原理”这些CPU和存储系统设计方法，其实都是在利用我们对于未来的“预测”，提前进行相应的操作，来提升我们的程序性能。